{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlolv/NLP_Project/blob/main/0_Data_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7468de",
      "metadata": {
        "id": "ae7468de"
      },
      "source": [
        "# Packages and definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c671b631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c671b631",
        "outputId": "a52d163d-6c58-4f50-e77c-deec27f80ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 20.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "DEVICE =  \u001b[34mCPU\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import requests as req\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from termcolor import colored\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "try :\n",
        "  import transformers\n",
        "except :\n",
        "  !pip install transformers\n",
        "  import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from itertools import compress\n",
        "import seaborn as sns\n",
        "from tqdm import *\n",
        "import time\n",
        "\n",
        "# torch.cuda.is_available() returns a boolean to check if the GPU can be used or not\n",
        "if torch.cuda.is_available():\n",
        "  # if CUDA is available set 'cuda' as the device\n",
        "  device = 'cuda'\n",
        "  # and then print the name of the GPU\n",
        "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
        "else:\n",
        "  # else, set 'cpu' as device\n",
        "  device = 'cpu'\n",
        "  # just print than the CPU is used. Alternatively you can check your CPU with the following command (linux based) in the next cell:\n",
        "  # ! lscpu\n",
        "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
        "\n",
        "git_url = \"https://raw.githubusercontent.com/chlolv/NLP_Project/main/Data/\"\n",
        "H1_url = \"H1.txt\"\n",
        "H2_url = \"H2.txt\"\n",
        "H3_url = \"H3.txt\"\n",
        "H4_url = \"H4.txt\"\n",
        "H5_url = \"H5.txt\"\n",
        "H6_url = \"H6.txt\"\n",
        "H7_url = \"H7.txt\"\n",
        "\n",
        "H1 = req.get(git_url + H1_url)\n",
        "H1 = H1.text\n",
        "H2 = req.get(git_url + H2_url)\n",
        "H2 = H2.text\n",
        "H3 = req.get(git_url + H3_url)\n",
        "H3 = H3.text\n",
        "H4 = req.get(git_url + H4_url)\n",
        "H4 = H4.text\n",
        "H5 = req.get(git_url + H5_url)\n",
        "H5 = H5.text\n",
        "H6 = req.get(git_url + H6_url)\n",
        "H6 = H6.text\n",
        "H7 = req.get(git_url + H7_url)\n",
        "H7 = H7.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f18d088",
      "metadata": {
        "id": "5f18d088"
      },
      "source": [
        "# Processing HP1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d65b69a5",
      "metadata": {
        "id": "d65b69a5"
      },
      "outputs": [],
      "source": [
        "H1_processed = H1\n",
        "H1_processed = H1_processed.split('\\r\\n\\r\\n')\n",
        "H1_processed = [sentence.strip() for sentence in H1_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(0, len(H1_processed)) :\n",
        "  paragraph = H1_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "    remove_list.append(i+1)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H1_processed[index]\n",
        "H1_processed = [paragraph for paragraph in H1_processed if paragraph not in [\"Harry Potter and the Sorcerer's Stone\", 'THE END']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35abca6e",
      "metadata": {
        "id": "35abca6e"
      },
      "source": [
        "# Processing HP2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fdb6a98d",
      "metadata": {
        "id": "fdb6a98d"
      },
      "outputs": [],
      "source": [
        "H2_processed = H2\n",
        "H2_processed = re.sub('\\r\\n[0-9]\\r\\n|\\r\\n[0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9][0-9]\\r\\n', ' ', H2_processed)\n",
        "H2_processed = re.sub('\\r\\n|\\r\\n.\\r\\n|\\r\\n..\\r\\n|\\r\\n...\\r\\n|\\r\\n....\\r\\n|\\r\\n.....\\r\\n', ' ', H2_processed)\n",
        "H2_processed = re.sub('\\*.\\*|\\*..\\*|\\*...\\*|\\*....\\*|\\*.....\\*|\\*......\\*|\\*.......\\*|\\*........\\*|\\*.........\\*|\\*..........\\*', '', H2_processed) \n",
        "H2_processed = H2_processed[202:]\n",
        "\n",
        "remove_list = []\n",
        "H2_processed = sent_tokenize(H2_processed)\n",
        "for i in reversed(range(1,len(H2_processed))) :\n",
        "  paragraph = H2_processed[i]\n",
        "  if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "    H2_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H2_processed[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b886f3e4",
      "metadata": {
        "id": "b886f3e4"
      },
      "source": [
        "# Processing HP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22e28cd8",
      "metadata": {
        "id": "22e28cd8"
      },
      "outputs": [],
      "source": [
        "H3_processed = H3\n",
        "H3_processed = re.sub('\\\\xad', '', H3_processed)\n",
        "H3_processed = H3_processed.split('\\r\\n\\r\\n')\n",
        "H3_processed = [paragraph.strip() for paragraph in H3_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H3_processed)) :\n",
        "  paragraph = H3_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H3_processed[index]\n",
        "\n",
        "remove_list = []\n",
        "for i in reversed(range(1,len(H3_processed))) :\n",
        "  paragraph = H3_processed[i]\n",
        "  try :\n",
        "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "      H3_processed[i-1] += ' ' + paragraph\n",
        "      remove_list.append(i)\n",
        "  except :\n",
        "    H3_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H3_processed[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f7ee34",
      "metadata": {
        "id": "35f7ee34"
      },
      "source": [
        "# Processing HP4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1b04ea3d",
      "metadata": {
        "id": "1b04ea3d"
      },
      "outputs": [],
      "source": [
        "H4_processed = H4\n",
        "H4_processed = re.sub('�', '-', H4_processed)\n",
        "H4_processed = H4_processed.split('\\n\\n')\n",
        "H4_processed = [paragraph.strip() for paragraph in H4_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H4_processed)) :\n",
        "  paragraph = H4_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H4_processed[index]\n",
        "\n",
        "H4_processed = H4_processed[2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9da3b82",
      "metadata": {
        "id": "f9da3b82"
      },
      "source": [
        "# Processing HP5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d3089c31",
      "metadata": {
        "id": "d3089c31"
      },
      "outputs": [],
      "source": [
        "H5_processed = H5\n",
        "H5_processed = re.sub('�', \"\\'\", H5_processed)\n",
        "H5_processed = H5_processed.split('\\n')\n",
        "H5_processed = [paragraph.strip() for paragraph in H5_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H5_processed)) :\n",
        "  paragraph = H5_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "    remove_list.append(i+1)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H5_processed[index]\n",
        "\n",
        "remove_list = []\n",
        "for i in reversed(range(1,len(H5_processed))) :\n",
        "  paragraph = H5_processed[i]\n",
        "  try :\n",
        "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "      H5_processed[i-1] += ' ' + paragraph\n",
        "      remove_list.append(i)\n",
        "  except :\n",
        "    H5_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H5_processed[index]\n",
        "\n",
        "H5_processed = H5_processed[2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e9a241",
      "metadata": {
        "id": "10e9a241"
      },
      "source": [
        "# Processing HP6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d3512250",
      "metadata": {
        "id": "d3512250"
      },
      "outputs": [],
      "source": [
        "H6_processed = H6\n",
        "H6_processed = H6_processed.split('\\n')\n",
        "H6_processed = [paragraph.strip() for paragraph in H6_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H6_processed)) :\n",
        "  paragraph = H6_processed[i]\n",
        "  if re.match('Chapter [0-9]', paragraph) :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H6_processed[index]\n",
        "\n",
        "H6_processed = H6_processed[32:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1a96ba",
      "metadata": {
        "id": "ce1a96ba"
      },
      "source": [
        "# Processing HP7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "11fa09a3",
      "metadata": {
        "id": "11fa09a3"
      },
      "outputs": [],
      "source": [
        "H7_processed = H7\n",
        "H7_processed = re.sub('�', \"\\'\", H7_processed)\n",
        "H7_processed = H7_processed.split('\\n')\n",
        "H7_processed = [paragraph.strip() for paragraph in H7_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H7_processed)) :\n",
        "  paragraph = H7_processed[i]\n",
        "  if paragraph[:7] == 'Chapter' :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H7_processed[index]\n",
        "\n",
        "H7_processed = H7_processed[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7503ca24",
      "metadata": {
        "id": "7503ca24"
      },
      "source": [
        "# Merging all HPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dde5653c",
      "metadata": {
        "id": "dde5653c"
      },
      "outputs": [],
      "source": [
        "taille_min_para = 30\n",
        "book_label_list = []\n",
        "H = []\n",
        "for book in range(1,8) :\n",
        "  current_H = globals()['H' + str(book) + '_processed']\n",
        "  remove_list = []\n",
        "  for i in reversed(range(0, len(current_H))) :\n",
        "    paragraph = current_H[i]\n",
        "    if len(paragraph.split()) < taille_min_para : # Split is on spaces (word count)\n",
        "      remove_list.append(i)\n",
        "      current_H[i-1] += ' '\n",
        "      current_H[i-1] += current_H[i]\n",
        "  for index in sorted(remove_list, reverse = True) :\n",
        "    del current_H[index]\n",
        "  for paragraph in current_H :\n",
        "      book_label_list.append(book)\n",
        "  H += current_H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2d438b21",
      "metadata": {
        "id": "2d438b21"
      },
      "outputs": [],
      "source": [
        "df_H = pd.DataFrame({'HP': H})\n",
        "df_book = pd.DataFrame({ 'book' : book_label_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dee5add9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dee5add9",
        "outputId": "71b23fc6-d185-4675-a8f7-15ec5d594b71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5156ea19-9a3e-44e0-8469-53b6071614a9\", \"H_series.csv\", 6334067)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b6e2cb8-ab41-4bfa-b569-16bfc79701ca\", \"book_labels.csv\", 41865)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "df_H.to_csv('H_series.csv', index = False)\n",
        "files.download('H_series.csv')\n",
        "\n",
        "df_book.to_csv('book_labels.csv', index = False)\n",
        "files.download('book_labels.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "0_Data_preprocess.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}