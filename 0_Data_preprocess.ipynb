{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7468de",
   "metadata": {},
   "source": [
    "# Packages and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c671b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chloe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chloe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE =  \u001b[34mCPU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "try :\n",
    "  import transformers\n",
    "except :\n",
    "  !pip install transformers\n",
    "  import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from itertools import compress\n",
    "import seaborn as sns\n",
    "from tqdm import *\n",
    "import time\n",
    "\n",
    "# torch.cuda.is_available() returns a boolean to check if the GPU can be used or not\n",
    "if torch.cuda.is_available():\n",
    "  # if CUDA is available set 'cuda' as the device\n",
    "  device = 'cuda'\n",
    "  # and then print the name of the GPU\n",
    "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
    "else:\n",
    "  # else, set 'cpu' as device\n",
    "  device = 'cpu'\n",
    "  # just print than the CPU is used. Alternatively you can check your CPU with the following command (linux based) in the next cell:\n",
    "  # ! lscpu\n",
    "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
    "\n",
    "git_url = \"https://raw.githubusercontent.com/chlolv/NLP_Project/main/Data/\"\n",
    "H1_url = \"H1.txt\"\n",
    "H2_url = \"H2.txt\"\n",
    "H3_url = \"H3.txt\"\n",
    "H4_url = \"H4.txt\"\n",
    "H5_url = \"H5.txt\"\n",
    "H6_url = \"H6.txt\"\n",
    "H7_url = \"H7.txt\"\n",
    "\n",
    "H1 = req.get(git_url + H1_url)\n",
    "H1 = H1.text\n",
    "H2 = req.get(git_url + H2_url)\n",
    "H2 = H2.text\n",
    "H3 = req.get(git_url + H3_url)\n",
    "H3 = H3.text\n",
    "H4 = req.get(git_url + H4_url)\n",
    "H4 = H4.text\n",
    "H5 = req.get(git_url + H5_url)\n",
    "H5 = H5.text\n",
    "H6 = req.get(git_url + H6_url)\n",
    "H6 = H6.text\n",
    "H7 = req.get(git_url + H7_url)\n",
    "H7 = H7.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18d088",
   "metadata": {},
   "source": [
    "# Processing HP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65b69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1_processed = H1\n",
    "H1_processed = H1_processed.split('\\r\\n\\r\\n')\n",
    "H1_processed = [sentence.strip() for sentence in H1_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(0, len(H1_processed)) :\n",
    "  paragraph = H1_processed[i]\n",
    "  if \"CHAPTER\" in paragraph :\n",
    "    remove_list.append(i)\n",
    "    remove_list.append(i+1)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H1_processed[index]\n",
    "H1_processed = [paragraph for paragraph in H1_processed if paragraph not in [\"Harry Potter and the Sorcerer's Stone\", 'THE END']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abca6e",
   "metadata": {},
   "source": [
    "# Processing HP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb6a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_processed = H2\n",
    "H2_processed = re.sub('\\r\\n[0-9]\\r\\n|\\r\\n[0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9][0-9]\\r\\n', ' ', H2_processed)\n",
    "H2_processed = re.sub('\\r\\n|\\r\\n.\\r\\n|\\r\\n..\\r\\n|\\r\\n...\\r\\n|\\r\\n....\\r\\n|\\r\\n.....\\r\\n', ' ', H2_processed)\n",
    "H2_processed = re.sub('\\*.\\*|\\*..\\*|\\*...\\*|\\*....\\*|\\*.....\\*|\\*......\\*|\\*.......\\*|\\*........\\*|\\*.........\\*|\\*..........\\*', '', H2_processed) \n",
    "H2_processed = H2_processed[202:]\n",
    "\n",
    "remove_list = []\n",
    "H2_processed = sent_tokenize(H2_processed)\n",
    "for i in reversed(range(1,len(H2_processed))) :\n",
    "  paragraph = H2_processed[i]\n",
    "  if paragraph[0].islower() or paragraph[0] == '.' :\n",
    "    H2_processed[i-1] += ' ' + paragraph\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H2_processed[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886f3e4",
   "metadata": {},
   "source": [
    "# Processing HP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e28cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_processed = H3\n",
    "H3_processed = re.sub('\\\\xad', '', H3_processed)\n",
    "H3_processed = H3_processed.split('\\r\\n\\r\\n')\n",
    "H3_processed = [paragraph.strip() for paragraph in H3_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(1, len(H3_processed)) :\n",
    "  paragraph = H3_processed[i]\n",
    "  if \"CHAPTER\" in paragraph :\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H3_processed[index]\n",
    "\n",
    "remove_list = []\n",
    "for i in reversed(range(1,len(H3_processed))) :\n",
    "  paragraph = H3_processed[i]\n",
    "  try :\n",
    "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
    "      H3_processed[i-1] += ' ' + paragraph\n",
    "      remove_list.append(i)\n",
    "  except :\n",
    "    H3_processed[i-1] += ' ' + paragraph\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H3_processed[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7ee34",
   "metadata": {},
   "source": [
    "# Processing HP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b04ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H4_processed = H4\n",
    "H4_processed = re.sub('�', '-', H4_processed)\n",
    "H4_processed = H4_processed.split('\\n\\n')\n",
    "H4_processed = [paragraph.strip() for paragraph in H4_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(1, len(H4_processed)) :\n",
    "  paragraph = H4_processed[i]\n",
    "  if \"CHAPTER\" in paragraph :\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H4_processed[index]\n",
    "\n",
    "H4_processed = H4_processed[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da3b82",
   "metadata": {},
   "source": [
    "# Processing HP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3089c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_processed = H5\n",
    "H5_processed = re.sub('�', \"\\'\", H5_processed)\n",
    "H5_processed = H5_processed.split('\\n')\n",
    "H5_processed = [paragraph.strip() for paragraph in H5_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(1, len(H5_processed)) :\n",
    "  paragraph = H5_processed[i]\n",
    "  if \"CHAPTER\" in paragraph :\n",
    "    remove_list.append(i)\n",
    "    remove_list.append(i+1)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H5_processed[index]\n",
    "\n",
    "remove_list = []\n",
    "for i in reversed(range(1,len(H5_processed))) :\n",
    "  paragraph = H5_processed[i]\n",
    "  try :\n",
    "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
    "      H5_processed[i-1] += ' ' + paragraph\n",
    "      remove_list.append(i)\n",
    "  except :\n",
    "    H5_processed[i-1] += ' ' + paragraph\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H5_processed[index]\n",
    "\n",
    "H5_processed = H5_processed[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9a241",
   "metadata": {},
   "source": [
    "# Processing HP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3512250",
   "metadata": {},
   "outputs": [],
   "source": [
    "H6_processed = H6\n",
    "H6_processed = H6_processed.split('\\n')\n",
    "H6_processed = [paragraph.strip() for paragraph in H6_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(1, len(H6_processed)) :\n",
    "  paragraph = H6_processed[i]\n",
    "  if re.match('Chapter [0-9]', paragraph) :\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H6_processed[index]\n",
    "\n",
    "H6_processed = H6_processed[32:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a96ba",
   "metadata": {},
   "source": [
    "# Processing HP7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fa09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H7_processed = H7\n",
    "H7_processed = re.sub('�', \"\\'\", H7_processed)\n",
    "H7_processed = H7_processed.split('\\n')\n",
    "H7_processed = [paragraph.strip() for paragraph in H7_processed]\n",
    "\n",
    "remove_list = []\n",
    "for i in range(1, len(H7_processed)) :\n",
    "  paragraph = H7_processed[i]\n",
    "  if paragraph[:7] == 'Chapter' :\n",
    "    remove_list.append(i)\n",
    "for index in sorted(remove_list, reverse = True) :\n",
    "  del H7_processed[index]\n",
    "\n",
    "H7_processed = H7_processed[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503ca24",
   "metadata": {},
   "source": [
    "# Merging all HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde5653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_min_para = 30\n",
    "book_label_list = []\n",
    "H = []\n",
    "for book in range(1,8) :\n",
    "  current_H = globals()['H' + str(book) + '_processed']\n",
    "  remove_list = []\n",
    "  for i in reversed(range(0, len(current_H))) :\n",
    "    paragraph = current_H[i]\n",
    "    if len(paragraph.split()) < taille_min_para : # Split is on spaces (word count)\n",
    "      remove_list.append(i)\n",
    "      current_H[i-1] += ' '\n",
    "      current_H[i-1] += current_H[i]\n",
    "  for index in sorted(remove_list, reverse = True) :\n",
    "    del current_H[index]\n",
    "  for paragraph in current_H :\n",
    "      book_label_list.append(book)\n",
    "  H += current_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d438b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H = pd.DataFrame({'HP': H})\n",
    "df_book = pd.DataFrame({ 'book' : book_label_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee5add9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e60768806e6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_H\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'H_series.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'H_series.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_book\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'book_labels.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "df_H.to_csv('H_series.csv', index = False)\n",
    "files.download('H_series.csv')\n",
    "\n",
    "df_book.to_csv('book_labels.csv', index = False)\n",
    "files.download('book_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff3848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
