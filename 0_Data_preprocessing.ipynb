{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Copie de Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlolv/NLP_Project/blob/main/0_Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package and definitions\n"
      ],
      "metadata": {
        "id": "OxWbBCciBuz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT\n",
        "# bi LSTM\n",
        "# Hierarchical cross-entropy ?\n",
        "# Bonne matrice de confusion\n",
        "\n",
        "import requests as req\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from termcolor import colored\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "try :\n",
        "  import transformers\n",
        "except :\n",
        "  !pip install transformers\n",
        "  import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from itertools import compress\n",
        "import seaborn as sns\n",
        "from tqdm import *\n",
        "import time\n",
        "\n",
        "# torch.cuda.is_available() returns a boolean to check if the GPU can be used or not\n",
        "if torch.cuda.is_available():\n",
        "  # if CUDA is available set 'cuda' as the device\n",
        "  device = 'cuda'\n",
        "  # and then print the name of the GPU\n",
        "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
        "else:\n",
        "  # else, set 'cpu' as device\n",
        "  device = 'cpu'\n",
        "  # just print than the CPU is used. Alternatively you can check your CPU with the following command (linux based) in the next cell:\n",
        "  # ! lscpu\n",
        "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
        "\n",
        "git_url = \"https://raw.githubusercontent.com/chlolv/NLP_Project/main/Data/\"\n",
        "H1_url = \"H1.txt\"\n",
        "H2_url = \"H2.txt\"\n",
        "H3_url = \"H3.txt\"\n",
        "H4_url = \"H4.txt\"\n",
        "H5_url = \"H5.txt\"\n",
        "H6_url = \"H6.txt\"\n",
        "H7_url = \"H7.txt\"\n",
        "\n",
        "H1 = req.get(git_url + H1_url)\n",
        "H1 = H1.text\n",
        "H2 = req.get(git_url + H2_url)\n",
        "H2 = H2.text\n",
        "H3 = req.get(git_url + H3_url)\n",
        "H3 = H3.text\n",
        "H4 = req.get(git_url + H4_url)\n",
        "H4 = H4.text\n",
        "H5 = req.get(git_url + H5_url)\n",
        "H5 = H5.text\n",
        "H6 = req.get(git_url + H6_url)\n",
        "H6 = H6.text\n",
        "H7 = req.get(git_url + H7_url)\n",
        "H7 = H7.text"
      ],
      "metadata": {
        "id": "DuRP4S1VEkGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2783a22-19c4-48e4-9e31-eb4055698b53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "DEVICE =  \u001b[32mTesla K80\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H1"
      ],
      "metadata": {
        "id": "sfOZiGShgD5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H1_processed = H1\n",
        "H1_processed = H1_processed.split('\\r\\n\\r\\n')\n",
        "H1_processed = [sentence.strip() for sentence in H1_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(0, len(H1_processed)) :\n",
        "  paragraph = H1_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "    remove_list.append(i+1)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H1_processed[index]\n",
        "H1_processed = [paragraph for paragraph in H1_processed if paragraph not in [\"Harry Potter and the Sorcerer's Stone\", 'THE END']]\n"
      ],
      "metadata": {
        "id": "x-3yCTTu_aeJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install GitPython\n",
        "# from git import Repo\n",
        "\n",
        "# repo_dir = 'C:/Users/chloe/OneDrive/Bureau/3A/NLP/Git/NLP_Project'\n",
        "# repo = Repo(repo_dir)\n",
        "# file_list = [\n",
        "#     'H1_processed',\n",
        "# ]\n",
        "# commit_message = 'Add H1'\n",
        "# repo.index.add(file_list)\n",
        "# repo.index.commit(commit_message)\n",
        "# origin = repo.remote('origin')\n",
        "# origin.push()"
      ],
      "metadata": {
        "id": "ntAo52wOWAdR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H2"
      ],
      "metadata": {
        "id": "gFPlA34WgN8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H2_processed = H2\n",
        "H2_processed = re.sub('\\r\\n[0-9]\\r\\n|\\r\\n[0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9]\\r\\n|\\r\\n[0-9][0-9][0-9][0-9][0-9]\\r\\n', ' ', H2_processed)\n",
        "H2_processed = re.sub('\\r\\n|\\r\\n.\\r\\n|\\r\\n..\\r\\n|\\r\\n...\\r\\n|\\r\\n....\\r\\n|\\r\\n.....\\r\\n', ' ', H2_processed)\n",
        "H2_processed = re.sub('\\*.\\*|\\*..\\*|\\*...\\*|\\*....\\*|\\*.....\\*|\\*......\\*|\\*.......\\*|\\*........\\*|\\*.........\\*|\\*..........\\*', '', H2_processed) \n",
        "H2_processed = H2_processed[202:]\n",
        "\n",
        "remove_list = []\n",
        "H2_processed = sent_tokenize(H2_processed)\n",
        "for i in reversed(range(1,len(H2_processed))) :\n",
        "  paragraph = H2_processed[i]\n",
        "  if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "    H2_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H2_processed[index]\n"
      ],
      "metadata": {
        "id": "17JDfOLggKpV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H3"
      ],
      "metadata": {
        "id": "HlaUIz56CO-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H3_processed = H3\n",
        "H3_processed = re.sub('\\\\xad', '', H3_processed)\n",
        "H3_processed = H3_processed.split('\\r\\n\\r\\n')\n",
        "H3_processed = [paragraph.strip() for paragraph in H3_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H3_processed)) :\n",
        "  paragraph = H3_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H3_processed[index]\n",
        "\n",
        "remove_list = []\n",
        "for i in reversed(range(1,len(H3_processed))) :\n",
        "  paragraph = H3_processed[i]\n",
        "  try :\n",
        "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "      H3_processed[i-1] += ' ' + paragraph\n",
        "      remove_list.append(i)\n",
        "  except :\n",
        "    H3_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H3_processed[index]\n"
      ],
      "metadata": {
        "id": "-mNX27UaCQ5-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H4"
      ],
      "metadata": {
        "id": "tQdzhVfpDiy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H4_processed = H4\n",
        "H4_processed = re.sub('ï¿½', '-', H4_processed)\n",
        "H4_processed = H4_processed.split('\\n\\n')\n",
        "H4_processed = [paragraph.strip() for paragraph in H4_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H4_processed)) :\n",
        "  paragraph = H4_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H4_processed[index]\n",
        "\n",
        "H4_processed = H4_processed[2:]\n"
      ],
      "metadata": {
        "id": "Fhu5pBG8Dkco"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H5"
      ],
      "metadata": {
        "id": "WFJWgi5ccsEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H5_processed = H5\n",
        "H5_processed = re.sub('ï¿½', \"\\'\", H5_processed)\n",
        "H5_processed = H5_processed.split('\\n')\n",
        "H5_processed = [paragraph.strip() for paragraph in H5_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H5_processed)) :\n",
        "  paragraph = H5_processed[i]\n",
        "  if \"CHAPTER\" in paragraph :\n",
        "    remove_list.append(i)\n",
        "    remove_list.append(i+1)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H5_processed[index]\n",
        "\n",
        "remove_list = []\n",
        "for i in reversed(range(1,len(H5_processed))) :\n",
        "  paragraph = H5_processed[i]\n",
        "  try :\n",
        "    if paragraph[0].islower() or paragraph[0] == '.' :\n",
        "      H5_processed[i-1] += ' ' + paragraph\n",
        "      remove_list.append(i)\n",
        "  except :\n",
        "    H5_processed[i-1] += ' ' + paragraph\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H5_processed[index]\n",
        "\n",
        "H5_processed = H5_processed[2:]\n",
        "\n"
      ],
      "metadata": {
        "id": "S6Li_TStct0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H6"
      ],
      "metadata": {
        "id": "fQTnL9k6fYEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H6_processed = H6\n",
        "H6_processed = H6_processed.split('\\n')\n",
        "H6_processed = [paragraph.strip() for paragraph in H6_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H6_processed)) :\n",
        "  paragraph = H6_processed[i]\n",
        "  if re.match('Chapter [0-9]', paragraph) :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H6_processed[index]\n",
        "\n",
        "H6_processed = H6_processed[32:]\n"
      ],
      "metadata": {
        "id": "87mfEIEVfaOD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traitement H7"
      ],
      "metadata": {
        "id": "8QtohO52g1VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H7_processed = H7\n",
        "H7_processed = re.sub('ï¿½', \"\\'\", H7_processed)\n",
        "H7_processed = H7_processed.split('\\n')\n",
        "H7_processed = [paragraph.strip() for paragraph in H7_processed]\n",
        "\n",
        "remove_list = []\n",
        "for i in range(1, len(H7_processed)) :\n",
        "  paragraph = H7_processed[i]\n",
        "  if paragraph[:7] == 'Chapter' :\n",
        "    remove_list.append(i)\n",
        "for index in sorted(remove_list, reverse = True) :\n",
        "  del H7_processed[index]\n",
        "\n",
        "H7_processed = H7_processed[1:]\n"
      ],
      "metadata": {
        "id": "c2QROLaZg2ts"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZW6N6-38ao9I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion des Hi"
      ],
      "metadata": {
        "id": "uwHDEM1FgW6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taille_min_para = 30\n",
        "book_label_list = []\n",
        "H = []\n",
        "for book in range(1,8) :\n",
        "  current_H = globals()['H' + str(book) + '_processed']\n",
        "  remove_list = []\n",
        "  for i in reversed(range(0, len(current_H))) :\n",
        "    paragraph = current_H[i]\n",
        "    if len(paragraph.split()) < taille_min_para : # Split is on spaces (word count)\n",
        "      remove_list.append(i)\n",
        "      current_H[i-1] += ' '\n",
        "      current_H[i-1] += current_H[i]\n",
        "  for index in sorted(remove_list, reverse = True) :\n",
        "    del current_H[index]\n",
        "  for paragraph in current_H :\n",
        "      book_label_list.append(book)\n",
        "  H += current_H\n"
      ],
      "metadata": {
        "id": "9tKTnKQxiSTd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_H = pd.DataFrame({'HP' : H})\n",
        "df_books = pd.DataFrame({'books' : book_label_list})"
      ],
      "metadata": {
        "id": "Biv_7sTCa7kg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df_H.to_csv('H_series.csv', index = False) \n",
        "df_books.to_csv('book_labels.csv', index = False)"
      ],
      "metadata": {
        "id": "kfcOrJj7Z4fi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('H_series.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L105XcwUa4fB",
        "outputId": "942cf0a1-1dc9-4f74-8e90-ed8aaea3b905"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_53fa07a2-e8d9-4729-ada8-e14f7ff2f151\", \"H_series.csv\", 6334067)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('book_labels.csv')"
      ],
      "metadata": {
        "id": "DilHbjs8sPp_",
        "outputId": "6895e519-9d71-4cac-a334-f408a8c281b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_370db5a6-c8bc-4482-a15e-96c1f9449587\", \"book_labels.csv\", 41866)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}