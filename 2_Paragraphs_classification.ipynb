{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/chlolv/NLP_Project/blob/main/Main%20notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxWbBCciBuz-"
   },
   "source": [
    "# Package and definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuRP4S1VEkGs",
    "outputId": "d8078a39-0c03-4879-812c-14769ec92497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chloe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chloe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE =  \u001b[34mCPU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "# bi LSTM\n",
    "# Hierarchical cross-entropy ?\n",
    "# Bonne matrice de confusion\n",
    "\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "try :\n",
    "  import transformers\n",
    "except :\n",
    "  !pip install transformers\n",
    "  import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from itertools import compress\n",
    "import seaborn as sns\n",
    "from tqdm import *\n",
    "import time\n",
    "\n",
    "# torch.cuda.is_available() returns a boolean to check if the GPU can be used or not\n",
    "if torch.cuda.is_available():\n",
    "  # if CUDA is available set 'cuda' as the device\n",
    "  device = 'cuda'\n",
    "  # and then print the name of the GPU\n",
    "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
    "else:\n",
    "  # else, set 'cpu' as device\n",
    "  device = 'cpu'\n",
    "  # just print than the CPU is used. Alternatively you can check your CPU with the following command (linux based) in the next cell:\n",
    "  # ! lscpu\n",
    "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
    "\n",
    "git_url = \"https://raw.githubusercontent.com/chlolv/NLP_Project/main/Data/\"\n",
    "H_url = \"H_series.csv\"\n",
    "book_url = \"book_labels.csv\"\n",
    "\n",
    "H = req.get(git_url + H_url)\n",
    "H = re.sub('\\n\\d{0,9}[0-9],',\n",
    "           '\\n', H.text[7:])\n",
    "# H = re.sub(\"',\",\n",
    "#            '', H)\n",
    "H = H.split('\\n')\n",
    "H = [para for para in H]\n",
    "\n",
    "book = req.get(git_url + book_url)\n",
    "book_label_list = re.sub('','0', book.text[6:])\n",
    "book_label_list = re.sub('010','1', book_label_list)\n",
    "book_label_list = re.sub('020','2', book_label_list)\n",
    "book_label_list = re.sub('030','3', book_label_list)\n",
    "book_label_list = re.sub('040','4', book_label_list)\n",
    "book_label_list = re.sub('050','5', book_label_list)\n",
    "book_label_list = re.sub('060','6', book_label_list)\n",
    "book_label_list = re.sub('070','7', book_label_list)\n",
    "book_label_list = book_label_list.split('\\n')\n",
    "\n",
    "book_label_list = [int(book) for book in book_label_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA64VX91SL-x"
   },
   "source": [
    "# Tache de classification des paragraphes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our algorithm to predict what characters are in the paragraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "aa40aadb291045708b5be55ff3326abd",
      "687a2f0f164d42c797ee6d5a674db6a9",
      "71a3bbd23b0c4b2d9339710288152780",
      "016dfc01ddc248f7a036e718de3867d2",
      "8c465b351ca34fb2b1d1ea1003be2f60",
      "05083d76c58b4ecc92f66aa659603284",
      "257290b0c45e4ee3b8f86bf9b0690690",
      "dafe0c2bfcec42a4857999005eea2e1d",
      "d420908c5531415ab6bedf4e79239df4",
      "746e14d6a58b4e79b7302cbff4db7a49",
      "0d50cd01236740e6917ab6a60efc2075"
     ]
    },
    "id": "H5p9DLlKDvFY",
    "outputId": "c72d32d4-85e6-4be0-ec1f-863f0fad7640"
   },
   "outputs": [],
   "source": [
    "# On se rammène à une tâche de classification\n",
    "character_list = {1: ['Harry', 'Potter'], 2: ['Ron', 'Weasley'], 3: ['Hermione', 'Granger'], 4: ['Snape', 'Severus'], \n",
    "                  5:['Albus', 'Dumbledore'], 6: ['Dursley', 'Vernon', 'Dudley', 'Petunia'], 7: ['Draco', 'Malfoy']}\n",
    "paragraph_character_labels = []\n",
    "special_data = []\n",
    "para_id = 0\n",
    "for paragraph in tqdm_notebook(H) :\n",
    "  paragraph_character_labels.append('')\n",
    "  for key in character_list.keys() :\n",
    "    character = character_list[key]\n",
    "    if any(name in paragraph for name in character) :\n",
    "      if paragraph_character_labels[para_id] != '' :\n",
    "        paragraph_character_labels[para_id] += '_'\n",
    "      paragraph_character_labels[para_id] += character[0]\n",
    "  if paragraph_character_labels[para_id] == '' :\n",
    "    paragraph_character_labels[para_id] += 'None'\n",
    "  para_id += 1\n",
    "pd.DataFrame.from_dict(Counter(paragraph_character_labels), orient = 'index').sort_values(by = [0], ascending = [False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "e27c8286baa24795bdf48113b1310961",
      "85e943f914b446fd87dd7fa77c4c4e81",
      "5ec4abe6f0cc4e06a94933112ee2b1fd",
      "76b4ac4ca9ae409c8b89a6d3c12e02f7",
      "7cf6b2dc48024affb54f7b9205f5c5d4",
      "873dd555ab7b473aa643e0ef9f691501",
      "87cff766ed61415e9170caa767625f8a",
      "8805049fd770481daae030c2648c46c4",
      "a30d6faba52040a88df588a77905943e",
      "5e9f2d8526be4305b3bc3505402bba12",
      "642c5542616144c7a75ff7b35620ae3d"
     ]
    },
    "id": "hdSq07ozujga",
    "outputId": "d509b04b-0380-4a67-eed6-2acd7ebefaf6"
   },
   "outputs": [],
   "source": [
    "# On masque les noms propres \n",
    "for paragraph in tqdm_notebook(H) :\n",
    "  tokenized = nltk.word_tokenize(paragraph)\n",
    "  proper_nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if pos in ['NNP', 'NNPS']] \n",
    "  for proper_noun in proper_nouns :\n",
    "      paragraph = re.sub(proper_noun, 'charoffocus', paragraph)\n",
    "  paragraph = re.sub('charoffocus charoffocus', 'charoffocus', paragraph)\n",
    "  paragraph = re.sub('charoffocus charoffocus', 'charoffocus', paragraph)\n",
    "  paragraph = re.sub('charoffocus charoffocus', 'charoffocus', paragraph)\n",
    "  special_data.append(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KImVlkIjJxyW"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "stratify_labels = []\n",
    "labels = paragraph_character_labels\n",
    "numeric_labels = pd.DataFrame(labels).replace(np.unique(labels), list(range(0, len(np.unique(labels)))))\n",
    "numeric_labels = list(numeric_labels[0])\n",
    "counted_data = pd.DataFrame.from_dict(Counter(paragraph_character_labels), orient = 'index').sort_values(by = [0], ascending = [False])\n",
    "data_that_matters = counted_data.index[(counted_data[0] > 500) & (counted_data.index != 'None')]\n",
    "for i in range(0, len(labels)) :\n",
    "  if labels[i] in data_that_matters :\n",
    "    new_label = labels[i] + '_' + str(book_label_list[i])\n",
    "  else :\n",
    "    new_label = 'Other' + '_' + str(book_label_list[i])\n",
    "  stratify_labels.append(new_label)\n",
    "counted_data = pd.DataFrame.from_dict(Counter(stratify_labels), orient = 'index').sort_values(by = [0], ascending = [False])\n",
    "data_that_matters = counted_data.index[(counted_data[0] > 100)]\n",
    "for i in range(0, len(labels)) :\n",
    "  if stratify_labels[i] not in data_that_matters :\n",
    "    stratify_labels[i] = 'Other' + '_' + str(book_label_list[i])\n",
    "numeric_stratify_labels = pd.DataFrame(stratify_labels).replace(np.unique(stratify_labels), list(range(1, len(np.unique(stratify_labels))+1)))\n",
    "numeric_stratify_labels = list(numeric_stratify_labels[0])\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(special_data, numeric_labels, \n",
    "                                                                    random_state=seed, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=numeric_stratify_labels)\n",
    "BOOL = [label in numeric_labels for label in temp_labels]\n",
    "temp_stratify_label = list(compress(numeric_stratify_labels, BOOL))\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=seed, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_stratify_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBOLNogdLkLG",
    "outputId": "b7d510cc-3c26-4108-903f-bf7991c061ca"
   },
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgAr6HRqLmQn"
   },
   "outputs": [],
   "source": [
    "new_tokens = ['charoffocus']\n",
    "num_added_toks = tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjJuvXhALvJ6",
    "outputId": "83a90ac8-b968-4b7c-bcc7-443e63403ec3"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 100\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text,\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text,\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text,\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wc69KjMORBO",
    "outputId": "5b957e3b-9dd4-4f80-e150-8a4ca8537ab9"
   },
   "outputs": [],
   "source": [
    "tokens_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVrSuKUAPaB6"
   },
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels)\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels)\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDJGtrQnPjf0"
   },
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 32\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZivGsEnLvV5"
   },
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sk2-NKG0QBxh"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "      super(BERT_Arch, self).__init__()\n",
    "      self.bert = bert       \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,len(np.unique(numeric_labels)))\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUvgs772fFeX"
   },
   "outputs": [],
   "source": [
    "bert.resize_token_embeddings(len(tokenizer))\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Vj3j_cZQB0-",
    "outputId": "fc022ed4-89dd-4537-d6f5-36a43bd323c8"
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4qtsMwKj4Ng"
   },
   "outputs": [],
   "source": [
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "# loss function\n",
    "#cross_entropy  = nn.NLLLoss(weight=weights) (a priori pas besoin puisque on a stratifié)\n",
    "cross_entropy  = nn.NLLLoss(reduction = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1ZLtB-6vNkH"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  model.train()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  # iterate over batches\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)**2\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD-x_eYSj9K9"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  print(\"\\nEvaluating...\")\n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "  # iterate over batches\n",
    "  for step, batch in enumerate(val_dataloader):\n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      # Calculate elapsed time in minutes.\n",
    "#      elapsed = format_time(time.time() - t0)\n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "      total_loss = total_loss + loss.item()\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "      total_preds.append(preds)\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-tJyM-SkAbO",
    "outputId": "5efa2d52-fb54-4090-e0d8-a6f69bb107d5"
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "model = model.to(device)\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 2\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9INFhlA2MbZI",
    "outputId": "937efbef-9e59-466c-d344-652fb9ee6204"
   },
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "xIRNgTlDMgPM",
    "outputId": "b15dd9a1-72a6-4e9c-a535-c4a61c206584"
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  # preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2kz_djvMiB0"
   },
   "outputs": [],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep88e9JCMjZx"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKlEV7MVTIiJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copie de Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016dfc01ddc248f7a036e718de3867d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_746e14d6a58b4e79b7302cbff4db7a49",
      "placeholder": "​",
      "style": "IPY_MODEL_0d50cd01236740e6917ab6a60efc2075",
      "value": " 20930/20930 [00:00&lt;00:00, 74150.07it/s]"
     }
    },
    "05083d76c58b4ecc92f66aa659603284": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d50cd01236740e6917ab6a60efc2075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "257290b0c45e4ee3b8f86bf9b0690690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e9f2d8526be4305b3bc3505402bba12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ec4abe6f0cc4e06a94933112ee2b1fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8805049fd770481daae030c2648c46c4",
      "max": 20930,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a30d6faba52040a88df588a77905943e",
      "value": 20930
     }
    },
    "642c5542616144c7a75ff7b35620ae3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "687a2f0f164d42c797ee6d5a674db6a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05083d76c58b4ecc92f66aa659603284",
      "placeholder": "​",
      "style": "IPY_MODEL_257290b0c45e4ee3b8f86bf9b0690690",
      "value": "100%"
     }
    },
    "71a3bbd23b0c4b2d9339710288152780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dafe0c2bfcec42a4857999005eea2e1d",
      "max": 20930,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d420908c5531415ab6bedf4e79239df4",
      "value": 20930
     }
    },
    "746e14d6a58b4e79b7302cbff4db7a49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76b4ac4ca9ae409c8b89a6d3c12e02f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e9f2d8526be4305b3bc3505402bba12",
      "placeholder": "​",
      "style": "IPY_MODEL_642c5542616144c7a75ff7b35620ae3d",
      "value": " 20930/20930 [01:19&lt;00:00, 286.53it/s]"
     }
    },
    "7cf6b2dc48024affb54f7b9205f5c5d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85e943f914b446fd87dd7fa77c4c4e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_873dd555ab7b473aa643e0ef9f691501",
      "placeholder": "​",
      "style": "IPY_MODEL_87cff766ed61415e9170caa767625f8a",
      "value": "100%"
     }
    },
    "873dd555ab7b473aa643e0ef9f691501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87cff766ed61415e9170caa767625f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8805049fd770481daae030c2648c46c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c465b351ca34fb2b1d1ea1003be2f60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a30d6faba52040a88df588a77905943e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa40aadb291045708b5be55ff3326abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_687a2f0f164d42c797ee6d5a674db6a9",
       "IPY_MODEL_71a3bbd23b0c4b2d9339710288152780",
       "IPY_MODEL_016dfc01ddc248f7a036e718de3867d2"
      ],
      "layout": "IPY_MODEL_8c465b351ca34fb2b1d1ea1003be2f60"
     }
    },
    "d420908c5531415ab6bedf4e79239df4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dafe0c2bfcec42a4857999005eea2e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e27c8286baa24795bdf48113b1310961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85e943f914b446fd87dd7fa77c4c4e81",
       "IPY_MODEL_5ec4abe6f0cc4e06a94933112ee2b1fd",
       "IPY_MODEL_76b4ac4ca9ae409c8b89a6d3c12e02f7"
      ],
      "layout": "IPY_MODEL_7cf6b2dc48024affb54f7b9205f5c5d4"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
